{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "empirical-crystal",
   "metadata": {},
   "source": [
    "# Merged Metadata Analysis\n",
    "\n",
    "In this analysis we are going to try and merge:\n",
    "- Prophage counts\n",
    "- GenBank data\n",
    "- RAST data\n",
    "- GTDB data\n",
    "- CheckV predictions\n",
    "\n",
    "So that we can filter by different things and identify interesting characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "killing-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import re\n",
    "\n",
    "from PhiSpyAnalysis import theils_u, DateConverter, printmd\n",
    "from PhiSpyAnalysis import read_phages, read_gtdb, read_checkv, read_base_pp, read_categories, read_metadata\n",
    "\n",
    "from scipy.stats import pearsonr, f_oneway\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
    "from sklearn import metrics\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, tukeyhsd, MultiComparison\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for parsing collection dates\n",
    "from dateutil.parser import parse, ParserError\n",
    "import pytz\n",
    "\n",
    "import subprocess\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-clinic",
   "metadata": {},
   "source": [
    "# Read the phage data. Check the version!\n",
    "\n",
    "We have two data sets: `small` is just 99 genomes and 1,561 phages and should run quickly for development. `not small` is all the data!\n",
    "\n",
    "Here we also convert all file names to just the `accession` and name the column `assembly_accession` so we can merge everything as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proof-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_small_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please note that this was run with git commit 46ed9e5 that has 567,404 genomes parsed.\n",
      "Initially there were 3,265,453 kept phages,but after filtering we kept 1,293,084 prophages from 176,702 genomes"
     ]
    }
   ],
   "source": [
    "phagesdf = read_phages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "improving-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf = read_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-highway",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}